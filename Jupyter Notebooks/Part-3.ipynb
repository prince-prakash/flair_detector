{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import praw\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarations\n",
    "flairs = ['AskIndia', 'Business/Finance', 'CAA-NRC-NPR', 'Coronavirus', 'Food', \n",
    "          'Non-Political', 'Photography', 'Policy/Economy', 'Politics',\n",
    "          'Scheduled', 'Science/Technology', 'Sports']\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted objections on text\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "  nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "  nb.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = nb.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "  #print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Support Vector Machine\n",
    "def linear_svm(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "  sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "                 ])\n",
    "  sgd.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = sgd.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "  #print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "def logisticreg(X_train, X_test, y_train, y_test):\n",
    "  logreg = []\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "  logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "                 ])\n",
    "  logreg.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = logreg.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "  #print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "def randomforest(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  \n",
    "  randfor = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                 ])\n",
    "  randfor.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = randfor.predict(X_test)\n",
    "  pickle.dump(randfor, open('LR.pkl', 'wb'))\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "  #print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier\n",
    "def mlpclassifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  \n",
    "  mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                 ])\n",
    "  mlp.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = mlp.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "  #print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Data\n",
    "def train_test(X,y):\n",
    " \n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "  print(\"Results of Naive Bayes Classifier\")\n",
    "  nb_classifier(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of Linear Support Vector Machine\")\n",
    "  linear_svm(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of Logistic Regression\")\n",
    "  logisticreg(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of Random Forest\")\n",
    "  randomforest(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of MLP Classifier\")\n",
    "  mlpclassifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g1zi21/coronavirus_covid19_megathread_news_and_updates_4/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4d2ix/monthly_happiness_thread_randians_please_share_a/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/tt6t9rjqhxt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/uca2xcdblzt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/fvgic0milxt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4ppv1/rip_prof_g_d_agarwal_a_selfless_ecowarrior_died/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://science.thewire.in/environment/ganga-river-lockdown-cleaner-namami-gange-sewage-treatment-ecological-flow/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.businesstoday.in/current/economy-politics/1000-foreign-firms-mull-production-in-india-300-actively-pursue-plan-as-exit-china-mantra-grows/story/401462.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/cities/mumbai/no-communal-angle-in-palghar-lynching-case-uddhav-thackeray/article31387021.ece\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/india/nisha-jindal-with-10k-fb-fans-turns-out-to-be-a-man/articleshow/75240983.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://m.timesofindia.com/business/india-business/vijay-mallya-loses-plea-against-his-extradition-in-uk-high-court/amp_articleshow/75249392.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://twitter.com/airnewsalerts/status/1252144570957209600?s=21\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thenewsminute.com/article/pray-home-during-ramzan-telangana-announces-strict-ban-religious-gatherings-122913\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://m.timesofindia.com/city/hyderabad/five-muslim-men-organise-last-rites-of-hindu-man-shunned-by-neighbours/articleshow/75242735.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4tv6h/showerthoughts_people_finding_old_demonetized/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.timesnownews.com/mirror-now/crime/article/after-arranging-food-for-family-by-selling-his-mobile-amid-lockdown-man-hangs-self/579855\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.progwithzee.com/post/a-45-day-old-becomes-the-youngest-in-india-to-die-of-coronavirus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thenewsminute.com/article/how-dr-simon-hercules-who-died-covid-19-chennai-was-denied-dignity-death-122947\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thequint.com/news/india/coronavirus-covid-19-violence-breaks-out-in-hotspot-in-bengaluru-padarayanapura-people-arrested\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.livemint.com/news/india/china-objects-to-india-tweaking-fdi-rules-says-move-violates-wto-norms-11587368297241.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.hindustantimes.com/india-news/out-of-money-6-foreigners-make-home-inside-cave-in-rishikesh-quarantined/story-H2UjZb7rtuqHayD8qcmRMI.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/lp7ev7gs30u41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thebetterindia.com/224049/ias-hero-indore-saraswati-river-revival-restore-sewage-clean-river-water-environment-india-gop94/amp/?__twitter_impression=true\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/bk0fba8havt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thekashmirmonitor.net/noted-female-photojournalist-in-kashmir-booked-under-uapa-for-fb-posts/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://scroll.in/latest/959732/covid-19-over-50-journalists-in-mumbai-test-positive-says-municipal-corporation\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.businessinsider.in/business/corporates/news/tcs-ceo-says-the-business-model-is-20-years-old-and-its-time-to-go-employee-lite/articleshow/75243124.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thequint.com/news/india/prima-facie-no-case-of-sedition-karnataka-hc-on-kashmiri-students-bt-venkatesh-bidar-amulya-leone\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4nhgb/three_hindu_men_in_karnataka_held_for_causing/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.hindustantimes.com/india-news/ima-warns-of-white-alert-black-day-over-violence-against-doctors/story-dZWief0bLk164WurbDl6jK.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/city/bhubaneswar/covid-19-landlady-in-odisha-waives-off-rent-for-seven-tenants/articleshow/75240164.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://twitter.com/ANI/status/1252098709187223558?s=09\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4r0tg/storyplease_dont_wait_too_long_to_tell_your_crush/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://twitter.com/mihirkotecha/status/1251551461659389952?s=20\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://twitter.com/ANI/status/1252162589158789120\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.hindustantimes.com/delhi-news/deoli-aap-mla-booked-for-extortion-abetment-of-suicide-case/story-fotqHRJSgeBLDunZXuWWQM.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://theprint.in/india/mamata-gives-rs-10-lakh-insurance-cover-to-journalists-asks-them-to-cover-positive-news/404062/?amp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/business/india-business/centre-gives-nod-to-convert-surplus-rice-stocks-into-ethanol/articleshow/75255342.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4si29/5_out_of_6_covid_positive_cases_today_in_kerala/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.timesnownews.com/mirror-now/crime/article/arunachal-pradesh-men-slaughter-king-cobra-for-feast-after-rice-gets-exhausted-amid-lockdown/580200\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4uvcv/the_communal_color_to_literally_every_incident/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4n0hx/is_it_only_the_common_people_who_have_to_abide_by/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.telegraphindia.com/india/coronavirus-lockdown-chemical-sprayed-into-mouth-worker-dies/cid/1766385\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4w43i/19m_i_am_fucked_literally_amid_lockdown/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.indiatoday.in/india/story/rajasthan-430-doctors-nurses-in-isolation-no-patient-on-ventilator-1667365-2020-04-15\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/1j1ufjnsszt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.indiatoday.in/india/story/chennai-neurosurgeon-dies-of-covid-19-mob-attacks-hearse-tries-to-stop-burial-1669076-2020-04-20\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.hindustantimes.com/india-news/india-under-lockdown-migrant-labourer-peddles-1-700-km-in-7-days-to-reach-home/story-FTrl4Jlc0K7HOxO63cyonM.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.mid-day.com/articles/those-lynched-were-carrying-rs-6-lakh-cash-which-is-now-missing/22739242\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.deccanherald.com/business/business-news/covid-19-outbreak-joblessness-rate-triples-to-over-20-827418.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/features/friday-review/music/The-path-lsquoJai-Horsquo-took/article16837170.ece\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/lk54kubalyt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.cnbctv18.com/healthcare/alcohol-sale-to-be-allowed-in-maharashtra-amid-coronavirus-lockdown-5734701.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4lrhm/people_stuck_with_their_family_during_the/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thenewsminute.com/article/pregnant-woman-bengaluru-walks-5-km-search-hospital-doctor-couple-save-baby-122905\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4oll7/psa_please_take_good_care_of_your_glasses/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.newindianexpress.com/cities/mumbai/2020/apr/20/at-least-53-journalists-in-mumbai-test-positive-for-coronavirus-says-bmc-2132839.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://mumbaimirror.indiatimes.com/coronavirus/news/covid-19-numbers-in-mumbai-are-likely-to-fall-by-next-week-but-that-may-not-necessarily-be-great-news/articleshow/75191043.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://m.timesofindia.com/city/bengaluru/karnataka-frothing-reduces-vrishabhavathi-water-crystal-clear-after-decades/articleshow/75150777.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.indiatoday.in/india/story/centre-writes-letter-to-kerala-govt-on-mha-lockdown-guidelines-violation-1668868-2020-04-20\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.mydigitalstartup.net/2020/04/20/government-video-conferencing/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.timesnownews.com/india/article/goa-becomes-coronavirus-free-after-last-active-case-tests-negative-no-new-case-since-april-3/580112\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.indiatoday.in/coronavirus-outbreak/story/coronavirus-killed-thousands-in-secret-too-countries-now-revising-covid-19-death-toll-1668946-2020-04-20\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/7ewkbad6ttt41.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.hindustantimes.com/delhi-news/covid-19-delhi-paid-the-price-of-markaz-incident-says-chief-minister-kejriwal/story-QoeGBpQ8GVlK5wUbfYVjTO_amp.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/india/rate-at-which-coronavirus-cases-doubling-in-india-slows-to-7-5-days-health-ministry/articleshow/75252306.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.vice.com/en_in/article/qjdye7/indians-forced-into-quarantine-are-dying-in-lockdownbut-not-from-coronavirus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://indianexpress.com/article/business/vijay-mallya-loses-appeal-in-uk-high-court-against-extradition-to-india-6370921/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.article-14.com/post/how-india-s-government-set-off-a-spiral-of-islamophobia\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/mrzqhorjvzt41.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/national/islamophobia-is-rising-in-india-says-organisation-of-islamic-cooperation/article31383624.ece/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/cities/chennai/in-chennai-doctors-burial-marred-by-protests-attacks/article31386195.ece?homepage=true\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4mpe2/my_fathers_boss_calling_him_to_join_business_from/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.talkesport.com/news/nodwin-gaming-host-under-scanner-for-allegedly-uttering-obscene-remarks-in-a-csgo-game/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.theweek.in/news/india/2020/04/20/kashmiri-woman-photojournalist-booked-over-anti-national-posts-on-facebook.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.altnews.in/video-of-currency-notes-found-on-indore-road-shared-with-false-claim-that-it-was-muslims-conspiracy-to-spread-coronavirus/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://m.timesofindia.com/city/hyderabad/five-muslim-men-organise-last-rites-of-hindu-man-shunned-by-neighbours/amp_articleshow/75242735.cms?__twitter_impression=true\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.ndtv.com/india-news/chattisgarh-im-in-custody-nisha-jindal-with-10-000-fb-followers-turns-out-a-man-2214596\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.youtube.com/watch?v=QdGEw_JCZkc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4qz1f/youtube_channel_for_class_x_mathematics_advises/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thenewsminute.com/article/kerala-man-arrested-sexually-abusing-his-6-year-old-granddaughter-122956\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.rediff.com/business/report/china-reacts-indias-fdi-rules-violate-wto-spirit/20200420.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.news18.com/news/buzz/mumbais-iconic-ramzan-food-market-to-be-off-menu-for-first-time-in-250-years-due-to-covid-19-2585199.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.businessinsider.in/careers/news/infosys-has-a-new-no-regret-policy-when-it-comes-to-employees/articleshow/75253715.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/india/home-minister-amit-shah-speaks-to-maharashtra-cm-on-palghar-lynching/articleshow/75254358.cms?utm_source=twitter.com&utm_medium=social&utm_campaign=TOIIndiaNews\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://i.redd.it/cfzc4622vyt41.png\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://filterkaapilive.com/2020/04/20/kcr-vijayan-chart-own-course-on-lockdown-ignore-centres-guidelines\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.moneycontrol.com/news/business/personal-finance/3-money-mistakes-to-avoid-during-the-coronavirus-pandemic-5137991.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.livemint.com/opinion/columns/there-is-a-reason-the-rest-of-india-cannot-be-kerala-11587312089722.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://indianexpress.com/article/india/kerala-several-test-positive-after-quarantine-for-four-weeks-6368851/lite\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/national/other-states/all-areas-in-pune-and-pimpri-chinchwad-to-be-sealed-till-april-27/article31384456.ece\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4pb9i/why_do_indian_men_love_to_pose_as_women_online/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/cities/Hyderabad/sans-aadhaar-no-ration-for-migrants/article31383356.ece\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4xetc/relevance_of_udemy_courses_in_the_job_sector/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4m70z/i_built_a_private_social_media_site_called_igloo/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://timesofindia.indiatimes.com/city/goa/with-strict-protocols-in-place-goa-partially-reopens-today/articleshow/75240681.cms\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.thehindu.com/news/national/islamophobia-is-rising-in-india-says-organisation-of-islamic-cooperation/article31383624.ece\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://pbs.twimg.com/media/EWA1Il4XgAEXhGa?format=jpg&name=medium\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://m.economictimes.com/industry/healthcare/biotech/pharmaceuticals/experts-criticise-indias-endorsement-for-use-of-hydroxychloroquine-on-covid-19-patients/amp_articleshow/75243316.cms?__twitter_impression=true\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"https://www.reddit.com/r/india/comments/g4wvwv/need_an_urgent_help_regarding_paytm/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "#Filling appropriate format for training purposes\n",
    "data = pd.read_csv('infom.csv')\n",
    "data['Flair'] = data['Flair'].fillna('Nothing')\n",
    "data['Title'] = data['Title'].apply(str)\n",
    "data['Title'] = data['Title'].apply(clean_text)\n",
    "data['Urls'] = data['Urls'].apply(str)\n",
    "data['Urls'] = data['Urls'].apply(clean_text)\n",
    "data['Comments'] = data['Comments'].apply(str)\n",
    "data['Comments'] = data['Comments'].apply(clean_text)\n",
    "combine = data['Title'] + data['Urls'] + data['Comments']\n",
    "data = data.assign(combine = combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title as Feature\n",
      "Results of Naive Bayes Classifier\n",
      "accuracy 0.5\n",
      "Results of Linear Support Vector Machine\n",
      "accuracy 0.55\n",
      "Results of Logistic Regression\n",
      "accuracy 0.5\n",
      "Results of Random Forest\n",
      "accuracy 0.6\n",
      "Results of MLP Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6\n",
      "Flair Detection using Urls as Feature\n",
      "Results of Naive Bayes Classifier\n",
      "accuracy 0.45\n",
      "Results of Linear Support Vector Machine\n",
      "accuracy 0.4\n",
      "Results of Logistic Regression\n",
      "accuracy 0.5\n",
      "Results of Random Forest\n",
      "accuracy 0.45\n",
      "Results of MLP Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n",
      "Flair Detection using Comments as Feature\n",
      "Results of Naive Bayes Classifier\n",
      "accuracy 0.45\n",
      "Results of Linear Support Vector Machine\n",
      "accuracy 0.35\n",
      "Results of Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n",
      "Results of Random Forest\n",
      "accuracy 0.35\n",
      "Results of MLP Classifier\n",
      "accuracy 0.4\n",
      "Flair Detection using Combined Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Deploying for testing the Models on\n",
    "data_fill = data.Flair\n",
    "W = data.Title\n",
    "X = data.Urls\n",
    "Y = data.Comments\n",
    "Z = data.combine\n",
    "print(\"Flair Detection using Title as Feature\")\n",
    "train_test(W,data_fill)\n",
    "print(\"Flair Detection using Urls as Feature\")\n",
    "train_test(X,data_fill)\n",
    "print(\"Flair Detection using Comments as Feature\")\n",
    "train_test(Y,data_fill)\n",
    "print(\"Flair Detection using Combined Features\")\n",
    "train_test(Z,data_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
